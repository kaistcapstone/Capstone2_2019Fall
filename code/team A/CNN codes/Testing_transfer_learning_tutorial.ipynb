{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing_transfer_learning_tutorial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"F2qZCL_9uLvZ","colab_type":"code","outputId":"940d75b7-c225-4198-af71-6fb889d7104d","executionInfo":{"status":"ok","timestamp":1571600062004,"user_tz":-540,"elapsed":38883155,"user":{"displayName":"DaeHo Lee","photoUrl":"","userId":"17169925910601933254"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# -*- coding: utf-8 -*-\n","\n","#Check Cuda Version\n","#!nvcc --version\n","\n","#!pip uninstall pytorch\n","#!pip uninstall pytorch-nightly\n","#!pip uninstall torchvision\n","\n","#Download Cuda 9.2 and PyTorch 0.4.1\n","#!git clone https://gist.github.com/f7b7c7758a46da49f84bc68b47997d69.git\n","#!bash /content/f7b7c7758a46da49f84bc68b47997d69/pytorch041_cuda92_colab.sh\n","\n","\n","\n","#!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n","#!pip3 install torchvision\n","\n","#!pip3 install --upgrade torch torchvision\n","\n","import torch\n","!nvcc --version\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","\n","\n","from __future__ import print_function, division\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import cv2\n","import torch.hub\n","from PIL import Image, ImageOps, ImageEnhance, PILLOW_VERSION\n","\n","#import fastai\n","\n","\n","\n","class adjust_brightness(object):\n","    def __init__(self, brightness_factor):\n","      self.brightness_factor = brightness_factor\n","    \n","    def __call__(self, img):\n","      enhancer = ImageEnhance.Brightness(img)\n","      img = enhancer.enhance(self.brightness_factor)\n","      return img    \n","\n","  \n","#print(torchvision.models.resnet.model_urls)\n","# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_transforms2 = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        #transforms.ColorJitter(brightness=0.6, contrast=0, saturation=0, hue=0),\n","        #transforms.RandomGrayscale(p=1),\n","        adjust_brightness(0.65),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        adjust_brightness(0.9),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = '/content/drive/My Drive/Colab Notebooks/notebook/catdog_data'\n","#data_dir = '/content/drive/My Drive/catdog_data'\n","save_path1 = '/content/drive/My Drive/Colab Notebooks/notebook/CNN_dogcat0810_SE-ResNet50_nondict5.pt'\n","save_path2 = '/content/drive/My Drive/Colab Notebooks/notebook/CNN_dogcat0810_SE-ResNet50_dict5.pt'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","image_datasets2 = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms2[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=24,\n","                                             shuffle=True, num_workers=16)\n","              for x in ['train', 'val']}\n","dataloaders2 = {x: torch.utils.data.DataLoader(image_datasets2[x], batch_size=24,\n","                                             shuffle=True, num_workers=16)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","######################################################################\n","# Visualize a few images\n","# ^^^^^^^^^^^^^^^^^^^^^^\n","# Let's visualize a few training images so as to understand the data\n","# augmentations.\n","\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs)\n","\n","# imshow(out, title=[class_names[x] for x in classes])\n","\n","\n","######################################################################\n","# Training the model\n","# ------------------\n","#\n","# Now, let's write a general function to train a model. Here, we will\n","# illustrate:\n","#\n","# -  Scheduling the learning rate\n","# -  Saving the best model\n","#\n","# In the following, parameter ``scheduler`` is an LR scheduler object from\n","# ``torch.optim.lr_scheduler``.\n","\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n","    since = time.time()\n","    print('Train start time is {}'.format(time.strftime('%c', time.localtime(since+32400))))\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    used_train_data_num = 0\n","    #print(used_train_data_num)\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                scheduler.step()\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                #used_train_data_num += 1\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                        \n","            #print(used_train_data_num)\n","\n","            \n","            for inputs, labels in dataloaders2[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        #optimizer.step()\n","                used_train_data_num += 1\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / 2 / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / 2 / dataset_sizes[phase]\n","\n","            \n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","            #print(used_train_data_num)\n","            time_elapsed = time.time() - since\n","            print('Time elapsed is {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","            \n","            \n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","\n","######################################################################\n","# Visualizing the model predictions\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","#\n","# Generic function to display predictions for a few images\n","#\n","\n","def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)\n","\n","######################################################################\n","# Finetuning the convnet\n","# ----------------------\n","#\n","# Load a pretrained model and reset final fully connected layer.\n","#\n","\n","\"\"\"Original Model Used\"\"\"\n","\"\"\"with pretrained=Flase, you'll need much, much \n","more epochs(often in hundreds) to get a good result\"\"\"\n","#model_ft = models.resnet18(pretrained=True)\n","\n","# New Model Used\n","#model_ft = models.resnet50(pretrained=True)\n","\n","#New Model test of SE-ResNet-50\n","#https://github.com/moskomule/senet.pytorch\n","#https://github.com/Xingxiangrui/various_pyTorch_network_structure/blob/master/senet_and_pretrained.py\n","\n","model_ft = torch.hub.load('moskomule/senet.pytorch', 'se_resnet50', pretrained=True,)\n","\n","\n","num_ftrs = model_ft.fc.in_features\n","model_ft.fc = nn.Linear(num_ftrs, 2)\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","\n","def testing_dataloader2(model, num_images=10):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders2['train']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                #ax = plt.subplot(num_images//2, 2, images_so_far)\n","                #ax.axis('off')\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        #model.train(mode=was_training)\n","\n","\n","\n","\n","# Observe that all parameters are being optimizedCNN_dogcat0810.pt\n","\n","# Original Optimizer Used\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.002, momentum=0.9)\n","\n","# New Optimizer Used_Performance Very Unsatisfactory\n","#optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.00002, betas = (0.9, 0.999), eps=1e-8)\n","\n","# Decay LR by a factor of 0.1 every 4 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n","\n","\"\"\"Use fixed LR for comparison\"\"\"\n","\n","#learn = create_cnn(image_datasets, models.resnet50, metrics=accuracy)\n","#learn.lr_find()\n","#learn.recorder.plot()\n","\n","######################################################################\n","# Train and evaluate\n","# ^^^^^^^^^^^^^^^^^^\n","#\n","# It should take around 15-25 min on CPU. On GPU though, it takes less than a\n","# minute.\n","#\n","\n","model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)\n","\n","\n","\n","######################################################################\n","#\n","\n","\n","#testing_dataloader2(model_ft)\n","\n","\n","\n","\n","#visualize_model(model_ft)\n","\n","# To resolve errors in CNN_test\n","torch.save(model_ft.state_dict(), save_path2)\n","\n","# Original code for saving\n","torch.save(model_ft, save_path1)\n","\n","\n","print('Saved model')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n","1.3.0+cu100\n","Tesla K80\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://github.com/moskomule/senet.pytorch/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\" to /root/.cache/torch/checkpoints/seresnet50-60a8950a85b2b.pkl\n","100%|██████████| 107M/107M [00:04<00:00, 27.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Train start time is Sun Oct 20 17:47:17 2019\n","Epoch 0/29\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["train Loss: 0.1104 Acc: 0.9537\n","Time elapsed is 20m 29s\n","val Loss: 0.0886 Acc: 0.9647\n","Time elapsed is 27m 25s\n","Epoch 1/29\n","----------\n","train Loss: 0.0825 Acc: 0.9664\n","Time elapsed is 45m 50s\n","val Loss: 0.0708 Acc: 0.9740\n","Time elapsed is 48m 54s\n","Epoch 2/29\n","----------\n","train Loss: 0.0699 Acc: 0.9714\n","Time elapsed is 67m 20s\n","val Loss: 0.0635 Acc: 0.9785\n","Time elapsed is 70m 24s\n","Epoch 3/29\n","----------\n","train Loss: 0.0635 Acc: 0.9741\n","Time elapsed is 89m 2s\n","val Loss: 0.0502 Acc: 0.9837\n","Time elapsed is 92m 9s\n","Epoch 4/29\n","----------\n","train Loss: 0.0599 Acc: 0.9755\n","Time elapsed is 110m 25s\n","val Loss: 0.0851 Acc: 0.9679\n","Time elapsed is 113m 27s\n","Epoch 5/29\n","----------\n","train Loss: 0.0607 Acc: 0.9752\n","Time elapsed is 131m 48s\n","val Loss: 0.0492 Acc: 0.9842\n","Time elapsed is 134m 51s\n","Epoch 6/29\n","----------\n","train Loss: 0.0566 Acc: 0.9765\n","Time elapsed is 153m 17s\n","val Loss: 0.0637 Acc: 0.9787\n","Time elapsed is 156m 20s\n","Epoch 7/29\n","----------\n","train Loss: 0.0501 Acc: 0.9800\n","Time elapsed is 174m 34s\n","val Loss: 0.0610 Acc: 0.9798\n","Time elapsed is 177m 37s\n","Epoch 8/29\n","----------\n","train Loss: 0.0453 Acc: 0.9823\n","Time elapsed is 195m 53s\n","val Loss: 0.0540 Acc: 0.9823\n","Time elapsed is 198m 56s\n","Epoch 9/29\n","----------\n","train Loss: 0.0436 Acc: 0.9819\n","Time elapsed is 217m 14s\n","val Loss: 0.0529 Acc: 0.9834\n","Time elapsed is 220m 17s\n","Epoch 10/29\n","----------\n","train Loss: 0.0418 Acc: 0.9828\n","Time elapsed is 238m 31s\n","val Loss: 0.0508 Acc: 0.9846\n","Time elapsed is 241m 38s\n","Epoch 11/29\n","----------\n","train Loss: 0.0382 Acc: 0.9841\n","Time elapsed is 259m 43s\n","val Loss: 0.0548 Acc: 0.9829\n","Time elapsed is 262m 49s\n","Epoch 12/29\n","----------\n","train Loss: 0.0389 Acc: 0.9842\n","Time elapsed is 280m 58s\n","val Loss: 0.0574 Acc: 0.9820\n","Time elapsed is 284m 0s\n","Epoch 13/29\n","----------\n","train Loss: 0.0397 Acc: 0.9842\n","Time elapsed is 302m 15s\n","val Loss: 0.0512 Acc: 0.9852\n","Time elapsed is 305m 18s\n","Epoch 14/29\n","----------\n","train Loss: 0.0389 Acc: 0.9839\n","Time elapsed is 323m 39s\n","val Loss: 0.0574 Acc: 0.9827\n","Time elapsed is 326m 42s\n","Epoch 15/29\n","----------\n","train Loss: 0.0368 Acc: 0.9853\n","Time elapsed is 344m 60s\n","val Loss: 0.0550 Acc: 0.9841\n","Time elapsed is 348m 3s\n","Epoch 16/29\n","----------\n","train Loss: 0.0396 Acc: 0.9840\n","Time elapsed is 366m 24s\n","val Loss: 0.0536 Acc: 0.9839\n","Time elapsed is 369m 27s\n","Epoch 17/29\n","----------\n","train Loss: 0.0370 Acc: 0.9853\n","Time elapsed is 387m 55s\n","val Loss: 0.0535 Acc: 0.9848\n","Time elapsed is 390m 59s\n","Epoch 18/29\n","----------\n","train Loss: 0.0390 Acc: 0.9839\n","Time elapsed is 409m 24s\n","val Loss: 0.0507 Acc: 0.9853\n","Time elapsed is 412m 27s\n","Epoch 19/29\n","----------\n","train Loss: 0.0381 Acc: 0.9846\n","Time elapsed is 430m 45s\n","val Loss: 0.0516 Acc: 0.9852\n","Time elapsed is 433m 47s\n","Epoch 20/29\n","----------\n","train Loss: 0.0384 Acc: 0.9847\n","Time elapsed is 452m 5s\n","val Loss: 0.0498 Acc: 0.9849\n","Time elapsed is 455m 7s\n","Epoch 21/29\n","----------\n","train Loss: 0.0363 Acc: 0.9856\n","Time elapsed is 473m 17s\n","val Loss: 0.0542 Acc: 0.9844\n","Time elapsed is 476m 26s\n","Epoch 22/29\n","----------\n","train Loss: 0.0356 Acc: 0.9852\n","Time elapsed is 494m 35s\n","val Loss: 0.0584 Acc: 0.9828\n","Time elapsed is 497m 45s\n","Epoch 23/29\n","----------\n","train Loss: 0.0358 Acc: 0.9855\n","Time elapsed is 515m 54s\n","val Loss: 0.0548 Acc: 0.9836\n","Time elapsed is 519m 4s\n","Epoch 24/29\n","----------\n","train Loss: 0.0384 Acc: 0.9843\n","Time elapsed is 537m 13s\n","val Loss: 0.0522 Acc: 0.9844\n","Time elapsed is 540m 23s\n","Epoch 25/29\n","----------\n","train Loss: 0.0376 Acc: 0.9847\n","Time elapsed is 558m 27s\n","val Loss: 0.0482 Acc: 0.9863\n","Time elapsed is 561m 36s\n","Epoch 26/29\n","----------\n","train Loss: 0.0360 Acc: 0.9852\n","Time elapsed is 579m 41s\n","val Loss: 0.0558 Acc: 0.9842\n","Time elapsed is 582m 46s\n","Epoch 27/29\n","----------\n","train Loss: 0.0359 Acc: 0.9853\n","Time elapsed is 601m 3s\n","val Loss: 0.0492 Acc: 0.9852\n","Time elapsed is 604m 8s\n","Epoch 28/29\n","----------\n","train Loss: 0.0350 Acc: 0.9854\n","Time elapsed is 622m 27s\n","val Loss: 0.0531 Acc: 0.9842\n","Time elapsed is 625m 32s\n","Epoch 29/29\n","----------\n","train Loss: 0.0377 Acc: 0.9853\n","Time elapsed is 643m 56s\n","val Loss: 0.0485 Acc: 0.9865\n","Time elapsed is 647m 2s\n","Training complete in 647m 2s\n","Best val Acc: 0.986514\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SEBottleneck. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SELayer. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["Saved model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dPEmPDlxoj05","colab_type":"code","outputId":"bc90339e-c7d0-4724-a3b3-d7e7bc315670","executionInfo":{"status":"ok","timestamp":1571561176184,"user_tz":-540,"elapsed":3275,"user":{"displayName":"DaeHo Lee","photoUrl":"","userId":"17169925910601933254"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]}]}